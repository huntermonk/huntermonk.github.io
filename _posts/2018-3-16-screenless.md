---
layout: post
title:  "Screenless Computing"
---

_Note: This post is pulled from a conversation I had. Naturally, it has a more conversational tone than other posts._

I really respect [Scott Galloway](https://www.l2inc.com/speakers/scott-galloway). His newsletter, [No Mercy No Malice](https://www.l2inc.com/daily-insights/no-mercy-no-malice/the-business-of-business-tv?utm_source=email&utm_medium=email&utm_content=nm2&utm_campaign=email) is one of my favorite two newsletters, the other is [Benedict Evan's](https://www.ben-evans.com).

A common theme of Scott's writing is the dominance of Amazon, and Alexa (or broadly, screenless computing) as the new computing platform. I also strongly believe in Amazon's domimance - it makes up ~60% of my portfolio.

I disagree that voice devices like Alexa are the new dominant form of computing.

Even if the Amazon Echo was perfect, meaning it always understood what you're saying, it still can only do a fraction of the things an iPhone can do. Also, there's nothing it can do that an iPhone can't.

Alexa can't show you videos, give you directions, or show you posts from your Instagram. You can add a screen to it, but then you just get to having a computer that you talk to. In that case, it's no different than Siri on the iPhone. So, voice-activated devices like HomePod and Alexa can and will become a big market, but not a transformative one like the iPhone.

Instead, something like AR glasses enables a totally different computing. If you had perfect AR glasses, you can go to Tokyo and everything you see and hear is translated for you all the time, which isn't possible with any other device.

